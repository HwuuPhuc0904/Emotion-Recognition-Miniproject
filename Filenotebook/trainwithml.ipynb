{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":472319,"sourceType":"datasetVersion","datasetId":218098}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom scipy.io import loadmat\n\n# Correct paths for Kaggle dataset\ndirectories = [\"/kaggle/input/seed-iv/eeg_feature_smooth/{}\".format(i+1) for i in range(3)] \nprint(directories)\n\nchannel_coords = [\n    ['0', '0', 'AF3', 'FP1', 'FPZ', 'FP2', 'AF4', '0', '0'], \n    ['F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8'], \n    ['FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8'], \n    ['T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8'], \n    ['TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8'], \n    ['P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8'], \n    ['0', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', '0'], \n    ['0', '0', 'CB1', 'O1', 'OZ', 'O2', 'CB2', '0', '0']\n]\n\nchannel_list = [\n    'FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', \n    'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', \n    'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', \n    'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', \n    'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', \n    'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', \n    'O1', 'OZ', 'O2', 'CB2'\n]\n\n# Verifying the length of channel coordinates\nprint(len(channel_coords), len(channel_coords[0]))\n\n# Creating a dictionary to map channel names to coordinates\ncoord_dict = {}\nfor n in range(len(channel_list)):\n    for i, l in enumerate(channel_coords):\n        for j, x in enumerate(l):\n            if channel_list[n] == x:\n                coord_dict[n] = (i, j)\nprint(coord_dict)\n\n# Initialize the array with the correct shape\nn = 24\nperSample = ['de_movingAve', 'de_LDS', 'psd_movingAve', 'psd_LDS']\narray = np.zeros(shape=(len(directories), len(os.listdir(directories[0])), n, 4, 8, 9, 5, 64)) \n\n# Iterate over directories to load and process data\nfor h, dire in enumerate(directories):\n    print(dire)\n    data = [loadmat(os.path.join(dire, file)) for file in os.listdir(dire)]\n    for i, bigsample in enumerate(data):\n        for j in range(n):\n            for k, key in enumerate(perSample):\n                # Transpose and pad the sample\n                sample = np.transpose(np.array(bigsample[key + str(j+1)]), (0, 2, 1))\n                sample = np.pad(sample, [(0, 0), (0, 0), (0, 64 - sample.shape[2])])\n                # Fill the array based on channel locations\n                for l, channel in enumerate(sample):\n                    array[h][i][j][k][coord_dict[l][0]][coord_dict[l][1]] = channel\n\n# Output the shape of the final array\nprint(array.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:27:44.883914Z","iopub.execute_input":"2024-12-13T09:27:44.884350Z","iopub.status.idle":"2024-12-13T09:27:55.557320Z","shell.execute_reply.started":"2024-12-13T09:27:44.884312Z","shell.execute_reply":"2024-12-13T09:27:55.556175Z"}},"outputs":[{"name":"stdout","text":"['/kaggle/input/seed-iv/eeg_feature_smooth/1', '/kaggle/input/seed-iv/eeg_feature_smooth/2', '/kaggle/input/seed-iv/eeg_feature_smooth/3']\n8 9\n{0: (0, 3), 1: (0, 4), 2: (0, 5), 3: (0, 2), 4: (0, 6), 5: (1, 0), 6: (1, 1), 7: (1, 2), 8: (1, 3), 9: (1, 4), 10: (1, 5), 11: (1, 6), 12: (1, 7), 13: (1, 8), 14: (2, 0), 15: (2, 1), 16: (2, 2), 17: (2, 3), 18: (2, 4), 19: (2, 5), 20: (2, 6), 21: (2, 7), 22: (2, 8), 23: (3, 0), 24: (3, 1), 25: (3, 2), 26: (3, 3), 27: (3, 4), 28: (3, 5), 29: (3, 6), 30: (3, 7), 31: (3, 8), 32: (4, 0), 33: (4, 1), 34: (4, 2), 35: (4, 3), 36: (4, 4), 37: (4, 5), 38: (4, 6), 39: (4, 7), 40: (4, 8), 41: (5, 0), 42: (5, 1), 43: (5, 2), 44: (5, 3), 45: (5, 4), 46: (5, 5), 47: (5, 6), 48: (5, 7), 49: (5, 8), 50: (6, 1), 51: (6, 2), 52: (6, 3), 53: (6, 4), 54: (6, 5), 55: (6, 6), 56: (6, 7), 57: (7, 2), 58: (7, 3), 59: (7, 4), 60: (7, 5), 61: (7, 6)}\n/kaggle/input/seed-iv/eeg_feature_smooth/1\n/kaggle/input/seed-iv/eeg_feature_smooth/2\n/kaggle/input/seed-iv/eeg_feature_smooth/3\n(3, 15, 24, 4, 8, 9, 5, 64)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"session1_label = [1,2,3,0,2,0,0,1,0,1,2,1,1,1,2,3,2,2,3,3,0,3,0,3]\nsession2_label = [2,1,3,0,0,2,0,2,3,3,2,3,2,0,1,1,2,1,0,3,0,1,3,1]\nsession3_label = [1,2,2,1,3,3,3,1,1,2,1,0,2,3,3,0,2,3,0,0,2,0,1,0]\nlabels = {0: 'neutral', 1: 'sad', 2: 'fear', 3: 'happy'}\n\ny = np.array(session1_label * 15 + session2_label * 15 + session3_label * 15)\n\nprint(y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:28:02.681808Z","iopub.execute_input":"2024-12-13T09:28:02.682668Z","iopub.status.idle":"2024-12-13T09:28:02.690334Z","shell.execute_reply.started":"2024-12-13T09:28:02.682626Z","shell.execute_reply":"2024-12-13T09:28:02.689173Z"}},"outputs":[{"name":"stdout","text":"(1080,)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"_X = array.reshape(np.prod(array.shape[0:3]), *array.shape[3:])\nprint(_X.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:28:04.773832Z","iopub.execute_input":"2024-12-13T09:28:04.774255Z","iopub.status.idle":"2024-12-13T09:28:04.780182Z","shell.execute_reply.started":"2024-12-13T09:28:04.774220Z","shell.execute_reply":"2024-12-13T09:28:04.779141Z"}},"outputs":[{"name":"stdout","text":"(1080, 4, 8, 9, 5, 64)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX = _X.transpose(0, 5, 1,2,3,4)\nprint(X.shape)\nX = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\nprint(X.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:28:07.184847Z","iopub.execute_input":"2024-12-13T09:28:07.185272Z","iopub.status.idle":"2024-12-13T09:28:08.100231Z","shell.execute_reply.started":"2024-12-13T09:28:07.185235Z","shell.execute_reply":"2024-12-13T09:28:08.098975Z"}},"outputs":[{"name":"stdout","text":"(1080, 64, 4, 8, 9, 5)\n(1080, 64, 1440)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"X_train_flat = X_train.reshape(X_train.shape[0], -1)  # (864, 64*1440)\nX_test_flat = X_test.reshape(X_test.shape[0], -1)    # (batch_size, 64*1440)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:28:10.330123Z","iopub.execute_input":"2024-12-13T09:28:10.330634Z","iopub.status.idle":"2024-12-13T09:28:10.783844Z","shell.execute_reply.started":"2024-12-13T09:28:10.330590Z","shell.execute_reply":"2024-12-13T09:28:10.782543Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_flat)\nX_test_scaled = scaler.transform(X_test_flat)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:28:12.649307Z","iopub.execute_input":"2024-12-13T09:28:12.650488Z","iopub.status.idle":"2024-12-13T09:28:14.075713Z","shell.execute_reply.started":"2024-12-13T09:28:12.650449Z","shell.execute_reply":"2024-12-13T09:28:14.074490Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Khởi tạo mô hình\nsvm_model = SVC(kernel='linear', C=1, gamma='scale')\n\n# Huấn luyện\nsvm_model.fit(X_train_scaled, y_train)\n\n# Dự đoán\ny_pred_svm = svm_model.predict(X_test_scaled)\n\n# Đánh giá\nprint(\"Accuracy (SVM):\", accuracy_score(y_test, y_pred_svm))\nprint(classification_report(y_test, y_pred_svm))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T09:30:35.609905Z","iopub.execute_input":"2024-12-13T09:30:35.610328Z","iopub.status.idle":"2024-12-13T09:30:56.974705Z","shell.execute_reply.started":"2024-12-13T09:30:35.610293Z","shell.execute_reply":"2024-12-13T09:30:56.973665Z"}},"outputs":[{"name":"stdout","text":"Accuracy (SVM): 0.7962962962962963\n              precision    recall  f1-score   support\n\n           0       0.72      0.87      0.79        45\n           1       0.78      0.78      0.78        50\n           2       0.79      0.74      0.76        65\n           3       0.90      0.82      0.86        56\n\n    accuracy                           0.80       216\n   macro avg       0.80      0.80      0.80       216\nweighted avg       0.80      0.80      0.80       216\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\n\nlog_reg_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000, random_state=42)\nlog_reg_multi.fit(X_train_scaled, y_train)\ny_pred_multi = log_reg_multi.predict(X_test_scaled)\n\nprint(\"Accuracy (Multinomial Logistic Regression):\", accuracy_score(y_test, y_pred_multi))\nprint(classification_report(y_test, y_pred_multi))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T20:39:30.191249Z","iopub.execute_input":"2024-12-12T20:39:30.191691Z","iopub.status.idle":"2024-12-12T20:44:59.639676Z","shell.execute_reply.started":"2024-12-12T20:39:30.191644Z","shell.execute_reply":"2024-12-12T20:44:59.638134Z"}},"outputs":[{"name":"stdout","text":"Accuracy (Multinomial Logistic Regression): 0.7777777777777778\n              precision    recall  f1-score   support\n\n           0       0.71      0.82      0.76        45\n           1       0.79      0.74      0.76        50\n           2       0.76      0.72      0.74        65\n           3       0.85      0.84      0.85        56\n\n    accuracy                           0.78       216\n   macro avg       0.78      0.78      0.78       216\nweighted avg       0.78      0.78      0.78       216\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}